---
title: "Model building"
author: "Ben Spycher"
format: ctupres-revealjs
# footer: |
#         CTU Bern theme for [Quarto Presentations](https://quarto.org/docs/presentations/revealjs/index.html).
#         Code available on [GitHub](https://github.com/aghaynes/CTUquarto).
chalkboard: false
self-contained: true

---

```{r setup, include=FALSE}
library(tidyverse)
library(broom)
library(ggplot2)
library(knitr)
library(RColorBrewer)
```

## Program overview

| Day | Time   | Topic                                                  |
|-----|--------|--------------------------------------------------------|
| Mon | AM     | Simple linear regression                               |
|     | PM     | Multiple linear regression                             |
| Tue | AM     | Introduction to logistic regression                    |
|     | **PM** | **Model building considerations and strategies**       |
| Wed | AM     | Models for stratified designs and categorical outcomes |
|     | PM     | Exercises, QA, wrap-up                                 |

## This afternoon's topics

|                                                                               |
|------------------------------------------------------------------------|
| **Model building considerations and strategies**
|	Testing (Wald and likelihood ratio tests)
|	Assessing linearity of association
|	Purposeful variable selection
|	Special issues in prediction modelling (calibration, discrimination, overfitting)


## Purpose of mulivariate models
Common reasons for including multiple independent variables are: 
* Risk factor modelling in analytic studies
    + Assessing dose-response relationship
    + Adjusting for confounding 
    + Identifying risk factors
* Prediction modelling 

## Steps in model building
Model building often includes at least on or multiple (if not all) following steps 

* Variable selection: Which independent variables to include
* Assessing linearity: Is the association of a continuous independent variable x with g(E(y)) linear?
* Modelling non-linear associations: If not, how should we model it? 
* Assessing interaction: Are there interactions between included variables?

Tools needed: Tests and model-selection criteria



## Maximum likelihood estimation

Recall our simple example: Nine of 12 household contacts of a SARS-CoV-2 positive index case also tested positive; the other 3 tested negative.   

Let's model the number of positive tests $Y$ as a binomial distribution with parameters $\pi$ (the unknown probability of a positive test) and $n=12$ (known):

$$P_{n,\pi}(Y=y)=\binom{n}{y}\pi^y(1-\pi)^{n-y}$$

## Maximum likelihood estimation

In ML estimation we estimate parameters by the values that maximise the 'likelihood' of the observed data. 

Formally, we maximize the *likelihood function*, which in our case is

$$\mathcal{L}(\pi|y=9, n=12)=P_{n=12,\pi}(Y=9)=\binom{12}{9} \pi^9(1-\pi)^{3}$$
*Note*: the likelihood function is a function of the parameter of interest given the observed data.


## Maximum likelihood estimation

ML estimator for the parameter $\pi$  of a binomial distribution $\hat{\pi}_{ML}=\frac{k}{n}$
```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
L<-function(p){
  choose(12,9)*p^9*(1-p)^(3)
  }
p<-seq(0,1,0.001)
Likelihood<-L(p)
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,Likelihood, type="l", col="green", xlab=expression(paste(pi)), lwd=2)
abline(v=9/12, lty=3, col="blue", lwd=2)
text(0.42, 0.021, expression(hat(pi)), col="blue")
text(0.60, 0.02, "=9/12=0.75",  col="blue")
```

## Sampling variability
![](pics/sampling_variation.jpg){fig-align="center"}

## Sampling variability of ML estimator

Frequency of k positive tests if the true probability were 0.75 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
rf<-dbinom(1:12,12, prob=0.75)
par(cex=1.3, mai=c(1,1,.5,.5))
barplot(rf, xlab="k", names.arg=1:12)
```




## Sampling variability of ML estimator

Each $k$ results in a different likelihood function and ML estimator. Dark colors in the graph indicate the most frequent (under repeated sampling) likelihood functions and ML estimates.

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-12
p<-seq(0,1,0.001)
rf<-dbinom(1:n,n, prob=0.75)
rf_max<-max(rf)
k<-1
Likelihood<-Lgen(k,n,p)
mypallete<-brewer.pal(9,"Greens")
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,Likelihood, type="l", col=mypallete[round(rf[k]*100)], xlab=expression(paste(pi)), lwd=2, ylim=c(0,0.5))
for (k in 1:n) {
  Likelihood<-Lgen(k,n,p)
  lines(p,Likelihood, type="l", col=mypallete[round(rf[k]/rf_max*9)], lwd=2)
  abline(v=k/n, lty=3, col=mypallete[round(rf[k]/rf_max*9)], lwd=2)
}

```



## Sampling variability of ML estimator

Increasing sample size increases precision (here $n=100$)

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-100
p<-seq(0,1,0.001)
rf<-dbinom(1:n,n, prob=0.75)
rf_max<-max(rf)
k<-1
Likelihood<-Lgen(k,n,p)
mypallete<-brewer.pal(9,"Greens")
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,Likelihood, type="l", col=mypallete[round(rf[k]*100)], xlab=expression(paste(pi)), lwd=2, ylim=c(0,0.12))
for (k in 1:n) {
  Likelihood<-Lgen(k,n,p)
  lines(p,Likelihood, type="l", col=mypallete[round(rf[k]/rf_max*9)], lwd=2)
  abline(v=k/n, lty=3, col=mypallete[round(rf[k]/rf_max*9)], lwd=2)
}

```



## Log-likelihood function
The log of the likelihood function has useful properties. Shown here the log-likelihood function $\ell(\pi)=\mathrm{log}(\mathcal{L}(\pi))$
for $k=75$ and $n=100$:

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-100
k<-75
p<-seq(0,1,0.001)
p0<-0.75
LogLikelihood<-log(Lgen(k,n,p))
approx<--0.5*n/(p0*(1-p0))*(p-p0)^2+max(LogLikelihood)
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,LogLikelihood, type="l", col="black", xlab=expression(paste(pi)), lwd=2, ylim=c(-50,0))
abline(v=k/n, lty=3, col="blue", lwd=2)
text(k/n-0.03, -48, expression(hat(pi)), col="blue")
```

## Quadratic approximation
In the peak region, the log-likelihood function (in green) is well approximated by a quadratic function (red) sharing the same curvature at the maximum.

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-100
k<-75
p<-seq(0,1,0.001)
p0<-0.75
LogLikelihood<-log(Lgen(k,n,p))
approx<--0.5*n/(p0*(1-p0))*(p-p0)^2+max(LogLikelihood)
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,LogLikelihood, type="l", col="black", xlab=expression(paste(pi)), lwd=2, ylim=c(-50,0))
lines(p,approx, type="l", col="red", lwd=2)
abline(v=k/n, lty=3, col="blue", lwd=2)
text(k/n-0.03, -48, expression(hat(pi)), col="blue")
text(0, -5, "Log likelihood", col="black", pos=4)
text(0, -10, "Quadratic approximation", col="red", pos=4)

```


## Fisher Information
The curvature of the log-likelihood function serves as a measure of "information" contained in the data about the parameter of interest. 

This measure is called *Fisher information*:  

$\mathcal{I}=-\mathrm{E}[\ell^{''}_i(\pi_0)]$

where $\mathrm{E}$ denotes the expectation and $\ell^{''}_i(\pi_0)$ is the second derivative of the log-likelihood function (for a single observation) evaluated at the true parameter $\pi_0$.

More generally, when there are $p$ parameters, $\mathcal{I}$ is a $p\times p$ matrix (*Fisher information matrix*).



## Standard error of the ML estimator
The $SE$  of the ML estimator is inversely related to the curvature of log-likelihood function at its maximum. 

Specifically, for large $n$, the $SE$ of the parameter is well approximated by

$$
SE_{\hat\pi_{ML}}\approx \frac{1}{\sqrt{n \cdot \mathcal{I}}}
$$

Importantly, the $SE$ decreases inverse proportionally with $\sqrt{n}$ (under certain conditions that are commonly satisfied).

## The ML estimator is consistent and asymptotically normal
Again under certain conditions and assuming that the data arose from the hypothesized distribution, the following holds: 

As $n$ increases, the ML estimator $\hat{\pi}_{ML}$ coverges to the true value $\pi_0$.

More specifically

$$
\sqrt{n}(\hat{\pi}_{ML}-\pi_0) \rightarrow \mathcal{N}(0,\frac{1}{\sqrt{\mathcal{I}}})
$$
This means that, for reasonably large sample sizes, the sampling distribution of $\hat{\pi}_{ML}$ is approximately normal with mean $\pi_0$ and variance $SE_{\hat\pi_{ML}}^2$.


## Testing procedures
Coming back to our example, let's assume we want to test the hypothesis:

$$H_0:\pi_0 =0.6$$
We will get to know two common testing procedures: 

* Wald tests: based on the quadratic approximation of the log-likelihood
* Likelihood ratio (LR) tests: based on the actual log-likelihood function

## Testing procedures

The LR-test statistic is the difference between the log-likelihood (scaled by factor 2) evaluated at its maximum and at the hypothesized parameter: $\lambda_{ML}=2(\ell(\hat{\pi}_{ML})-\ell(\pi_0))$. 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-100
k<-75
p<-seq(0,1,0.001)
p0<-0.75
ph0<-0.6
LogLikelihood<-log(Lgen(k,n,p))
lmax<-max(LogLikelihood)
approx<--0.5*n/(p0*(1-p0))*(p-p0)^2+lmax
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,2*LogLikelihood, type="l", col="black", xlab=expression(pi), ylab="2 x log-likelihood", lwd=2, ylim=c(-20,-3))
lines(p,2*approx, type="l", col="red", lwd=2)
abline(v=k/n, lty=3, col="blue", lwd=2)
text(k/n-0.03, -19, expression(hat(pi)), col="blue")
abline(h=2*lmax, lty=3, col="blue", lwd=2)
abline(v=0.6, lty=3, col="blue", lwd=2)
text(0.6+0.03, -19.6, expression(pi[0]), col="blue")
lines(ph0-c(0.004,0.004),c(2*lmax,2*log(Lgen(k,n,0.6))), col="black", lwd=4)
#lines(ph0+c(0.004,0.004),c(2*lmax,-n/(p0*(1-p0))*(ph0-p0)^2+2*lmax), col="red", lwd=4)
text(ph0-0.06, -7, expression(lambda[LR]), col="black")
#text(ph0+0.04, -6.8, expression(z^2), col="red")
text(0, -10, "Log likelihood", col="black", pos=4)
text(0, -12, "Quadratic approximation", col="red", pos=4)

```



## Testing procedures
The same evaluations based on the quadratic approximation yield the Wald test statistic $z^2$. Under $H_0$ and repeated sampling, both $z^2$ and $\lambda_{ML}$ are approximately (for large $n$) $\chi^2$-distributed with 1 df. 


```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
Lgen<-function(k,n,p){
  choose(n,k)*p^k*(1-p)^(n-k)
}
n<-100
k<-75
p<-seq(0,1,0.001)
p0<-0.75
ph0<-0.6
LogLikelihood<-log(Lgen(k,n,p))
lmax<-max(LogLikelihood)
approx<--0.5*n/(p0*(1-p0))*(p-p0)^2+lmax
par(cex=1.3, mai=c(1,1,.5,.5))
plot(p,2*LogLikelihood, type="l", col="black", xlab=expression(pi), ylab="2 x log-likelihood", lwd=2, ylim=c(-20,-3))
lines(p,2*approx, type="l", col="red", lwd=2)
abline(v=k/n, lty=3, col="blue", lwd=2)
text(k/n-0.03, -19, expression(hat(pi)), col="blue")
abline(h=2*lmax, lty=3, col="blue", lwd=2)
abline(v=0.6, lty=3, col="blue", lwd=2)
text(0.6+0.03, -19.6, expression(pi[0]), col="blue")
lines(ph0-c(0.004,0.004),c(2*lmax,2*log(Lgen(k,n,0.6))), col="black", lwd=4)
lines(ph0+c(0.004,0.004),c(2*lmax,-n/(p0*(1-p0))*(ph0-p0)^2+2*lmax), col="red", lwd=4)
text(ph0-0.06, -7, expression(lambda[LR]), col="black")
text(ph0+0.04, -6.8, expression(z^2), col="red")
```

## Chi-squared distribution
Consider $Z_1, Z_2, \dots, Z_k$ independently sampled from the standard normal distribution. The sum of squares $Q=\sum_{i=1}^k Z_i^2$ is then chi-squared distributed with $k$ degrees of freedom. 

Plot of the chi-square distribution for values of $k = 1, 2,\dots, 9$

![Source:<http://commons.wikimedia.org/wiki/User:Geek3>](pics/Chi-square.png){width=80%}


## Wald test
In the case of a single parameter, the square root of the Wald statistic becomes our familiar z-statistic 
$$
z=  \frac{\hat{\pi}_{ML}-\pi_0}{\hat{SE}}
$$
and can be compared with the standard normal distribution.

In our example, $\hat{SE}=\sqrt{\frac{\hat{\pi}_{ML}(1-\hat{\pi}_{ML})}{n}}$ and hence $z=3.4641$ resulting in a p-value of 0.000532.

We can safely reject $H_0$.





## LR-test - single parameter case
We refer to the ratio of the likelihood function for two given parameter values $\pi_1$ and $\pi_2$ as the likelihood ratio $LR=\frac{\mathcal{L}(\pi_0)}{\mathcal{L}(\hat{\pi}_{ML})}$.

The LR-test statistic is 2 times the negative LR with comparing the restricted parameter value under $H_0$ with ML estimate:   
$$
\lambda_{LR}=  -2(\ell(\pi_0) - \ell(\hat{\pi}_{ML}))=-2\cdot \mathrm{log}\left( \frac{\mathcal{L}(\pi_0)}{\mathcal{L}(\hat{\pi}_{ML})}\right)=-2\cdot \mathrm{log}\left(LR\right)
$$
Under $H_0$, $\lambda_{LR}$ follows a $\chi^2$ distribution with 1 df. 

Here $\ell(\pi_0)=-7.3738$ and $\ell(\hat{\pi}_{ML})=-2.3881$  and hence $\lambda_{LR}=9.9714$ resulting in a p-value of 0.00159. Again, we can safely reject $H_0$.


## LR-test - general case
When there are multiple parameters, we can test multiple restrictions. 

Example: In the logistic regression model 
$$\text{logit}(\pi(x_1, x_2,\dots,x_k))=\beta_0 + \beta_1 x_1 +\beta_2 x_2 +\dots +\beta_k x_k$$
we may wish to test $H_0: \beta_1=\beta_2=\beta_3=0$.

Under $H_0$, LR statistic $\lambda_{LR}=  -2(\ell(\hat{\boldsymbol\beta}_{H_0}) - \ell(\hat{\boldsymbol\beta}))$
follows a $\chi^2$ distribution with 3 df (3 restrictions). 

Here $\hat{\boldsymbol\beta}$ stands for the vector of fitted parameters of the full model $\hat{\boldsymbol\beta}_{H_0}$ for those of the restricted model under $H_0$ (i.e dropping the first 3 variables).



## Tests in standard glm output
Output using `summary` command: 

```{r}
#| echo: false
#| eval: true
dat <- read.csv("data/onch1302.csv", sep=";")
dat <- dat |> dplyr::select(mf, agegrp, area) |>
  mutate(mf = factor(mf, levels=c(0, 1), labels=c("No", "Yes")),
         agegrp = factor(agegrp, levels=c(0, 1, 2, 3), labels=c("5–9", "10–19", "20–39", "40+")), 
         area = factor(area, levels=c(0, 1), labels=c("Savannah", "Rainforest")))

dat$area<-relevel(dat$area, "Savannah")
```

```{r}
#| echo: true
#| eval: true
mod<-glm(mf~area + agegrp, data=dat, family=binomial(link="logit"))
summary(mod)
```
## Tests in standard glm output
We can also use the `tidy` and `glance` functions from the `broom` package to view the glm object
```{r}
#| echo: true
#| eval: true
tidy(mod)
glance(mod)
```

## Tests in standard glm output
The z-value and p-values reported for each estimate refer to the Wald test for the null-hypothesis that the corresponding $\beta$-parameter is zero:  $H_0: \beta_i=\beta_{H_0}= 0$. 

Example: The z-statistic for the `areaRainforest` parameter is: 

$$z= \frac{\hat{\beta}_1-\beta_{H_0}}{\hat{SE}(\hat{\beta}_1)}=\frac{1.1260-0}{0.1376}=8.181$$
The area under the standard normal curve beyond $|z|$ gives the two-sided p-value as reported
```{r}
#| echo: true
#| eval: true
output<-tidy(mod)
2*pnorm(-abs(output$estimate[2]/output$std.error[2]))
```


## Tests in standard glm output
Interpretation of null-hypothesis   $H_0: \beta_i= 0$: 

- For intercept,  $\beta_0= 0$ means that the baseline odds is 1.
- For a slope coefficient,  $\beta_i= 0$ means that the corresponding OR is 1.

We can safely reject the hypothesis that the odds of microfilarial infection is the same in rainforest areas as in savannah areas.


## Deviance 

The deviance of a model is given by: 

$$D=-2(\ell(\hat{\boldsymbol\beta}) - \ell(\hat{\boldsymbol\beta}_{S}))$$

Where $\hat{\boldsymbol\beta}$ is the vector fitted parameters of the model in question, and $\hat{\boldsymbol\beta}_{S}$ that of the saturated model. 

The *saturated model* is one that has a parameter for every observation and thus fits the data exactly. 

The deviance is a generalization of the residual sum of squares (RSS) in linear regression. For the linear model, $D=\text{RSS}$.

## Global LR-test

The standard output reports the deviance of the fitted model ("residual deviance", denoted here as $D$) and the null model ("null deviance", $D_{H_0}$), which includes the intercept only. 

We can use these to run an LR-test for the null-hypothesis: 

$$H_0=\beta_1 = \beta_2 =\dots =\beta_k =0$$
The test statistic is simply the difference in deviance: 

 $$\lambda_{LR}= -2(\ell(\hat{\boldsymbol\beta}_{H_0}) - \ell(\hat{\boldsymbol\beta}))=D_{H_0}-D $$

and can be compared to  $\chi^2$ distribution with $k$ df.


## Global LR-test
Thus we can directly compute the global LR-test from the output data: 


```{r}
#| echo: true
#| eval: true
out<-unlist(glance(mod))
out
(lambda <- unname(out["null.deviance"]-out["deviance"]))
(df <-  unname(out["df.null"]-out["df.residual"]))
(P <- pchisq(lambda, df, lower.tail = FALSE))
```

## Global LR-test
In our example, $D = 1384.8$ and $D_0=1714.1$. Thus the test statistic is $\lambda_{LR}=1714.1-1384.8=329.3$. 

We can use the `anova` command to run the test: 


```{r}
#| echo: true
#| eval: true
mod<-glm(mf~area + agegrp, data=dat, family=binomial(link="logit"))
mod_0<-glm(mf~1, data=dat, family=binomial(link="logit"))
lrt <- anova(mod_0, mod, test="LRT")
lrt
# Exact p-value
lrt[["Pr(>Chi)"]]

```

## LR-test vs. Walt test
* LR-test is generally recommended as it is based on the actual likelihood ratio
* The LR-test plays the same role in GLMs as the F-test in linear models
* (Partial) LR-test usually require fitting the model twice (unrestricted and restricted model)
* The Wald test avoids this by using a quadratic approximation of the likelihood function
* For this reason, the Wald tests for single parameters are shown in standard regression output 

## LR test for interaction
Recall our model for interaction 

```{r}
#| echo: true
#| eval: true
mod_int<-glm(mf~area*agegrp, data=dat, family=binomial(link="logit"))
summary(mod_int)
```

## LR test for interaction
We can use the LR-test to test whether their is interaction. 

The null-hypothesis statest that the $\beta$-parameters of all 3 interaction terms are 0. 

```{r}
#| echo: true
#| eval: true
anova(mod, mod_int, test="LRT")
```

We find no evidence for interaction between area and age group (P = 0.1531)


## Variable selection
Criteria for including/excluding variables depend on the modelling purpose. Choose your strategy before starting!

* Risk factor modelling
  + Single exposure of interest (confirmatory)
    - Emphasis on prior knowledge & causal reasoning (DAGs)
  + Risk factor identification (exploratory)
    - Combination of prior knowledge and statistical criteria
* Prediction modelling 
    - Usually a stronger emphasis on statistical criteria

## Single exposure
The interest lies in assessing a causal association between an outcome and a single exposure. 

* Risks for biases should be minimized at the design level
* Assess potential confounding factors based on prior knowledge (e.g. using a DAG)
* Adjust for measured potential counfounders in model 
* Optionally, exclude variables that don't confound or contribute to model fit
* Assess functional form of dose-response (on logit scale) 


## Risk factor identification
The interest lies in identifying relevant risk/protective factors from a set variables suspected to be influential. No causal assumptions made. 

* Include potential risk factors based on prior knowledge
* Variable selection strategy should combine subject knowledge and statistical criteria
* "Purposeful selection" is a common approach (with variations) as outlined below

## Prediction models
The interest lies predicting outcomes based on a given set of covariates. No specific causal assumptions are made.  

* Include potential predictors based on prior knowledge
* Variable selection strategy should combine subject knowledge and statistical criteria - the multiplicity of plausible models is usually an incentive for greater reliance on the latter
* A major challenge is to avoid overfitting
* Internal & external validation is necessary


## Overfitting 
Overfitting refers to the situation, where the model captures idiosyncrasies in the dataset. This is usually a problem when the number of (candidate) predictors in relation to the sample size. 

Signs of overfitting

- Large standard errors, numerically unstable estimates
- Optimism: Prediction performance will be lower when the model is applied to a new sample (shrinkage)

For a discussion of these issues see this [tutorial on multivariable prognostic models](https://doi.org/10.1002/(SICI)1097-0258(19960229)15:4%3C361::AID-SIM168%3E3.0.CO;2-4) by Frank Harrel et al. 


## Overfitting 
Model selection does not solve the problem. The coefficients of variables selected from a large number of predictors based on statistical criteria tend to be biased, because these tend to be the ones that best capture ideosyncrasies in the dataset.

Sample size requirement to avoid overfitting:  

- A common rule of thumb: $\geq 10$ events per candidate predictor 
- Recent research suggest more tailored and stringent approach: 
    * see [here](https://doi.org/10.1002/sim.7993) for continuous outcomes
    * see [here](https://doi.org/10.1002/sim.7992) for binary and time-to event outcomes


## Occam's razor
*"Entities must not be multiplied beyond necessity"* (Attributed to English philosopher and theologian William of Ockham)

In Isaac Newton's words: *"We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances"*

* In statistical modelling, we commonly seek the most *parsimonous* (fewest parameters) model that still accurately reflects the data. 

* The challenge is to isolate effects the phenomenon of interest from those of other causes and "random" variability.



## Model selection criteria
Many statistical criteria have been proposed to facilitate model selection. 

In addition to statistical tests such as the LR-test, two popular criteria are the *Akaike information criterion* (AIC) and the *Bayesian information criterion* (BIC)

In contrast to the LR-test (or F-test), the AIC and BIC can compare non-nested models, i.e. in situations, where neither of the models can be formulated as a restriction of the other. 

The AIC and BIC both aim to strike a balance between model fit and parsimony. 

## Akaike Information Criterion (AIC)
The AIC is defined as

$$\text{AIC}=2k-2\hat{\ell}$$
where k is the number of parameters in the model. For logistic regression, this includes all $\beta$ parameters (including intercept) and in linear regression all $\beta$ parameters plus the residual variance. 

The model with minimum AIC value is preferred.  The term $2k$ penalizes model complexity while $2\hat{\ell}$ rewards model fit. 


## Bayesian Information Criterion (BIC)
The BIC is defined as

$$\text{BIC}=k\ln(n)-2\hat{\ell}$$
The BIC places a higher penalty on model complexity. 

The model with minimum BIC value is preferred.  



## AIC vs. BIC
There are not clear-cut rules when which criterion to use. However: 

- BIC will tend to choose the correct model (as $n\rightarrow \infty$) if it is indeed among the candidate models. Generally preferred when the purpose is inference

- AIC will tend chose the best approximating model in terms of prediction error (as $n\rightarrow \infty$). Generally preferred when the purpose is prediction


## Purposeful selection
With slight variation, we the approach "purposeful selection" from the book [Applied Logistic Regression](https://onlinelibrary.wiley.com/doi/book/10.1002/9781118548387) by Stanley Lemeshow (Chapter 4.2)

We demonstrate the steps using the `Caerphilly dataset` which contains data on 1786 men who took part in the Caerphilly cohort study in Wales, a study of risk factors for cardiovascular disease. 

- Our objecive: identify risk factors for the outcome myocardial infarction (`mi`). 

- We (falsely) assume here that all men are followed-up for the same amount of time (probabilities can be interpreted as risks). 

## Caerphilly dataset 
Potential risk factors considered: social class (`socclass`, 6 levels), diabetes (`diabetes`) smoking history and current smoking (`smoking`, `cursmoke`), blood levels of fibrinogen (`fibrin`), total cholesterol (`totchol`), HDL cholesterol (`hdlchol`), systolic and diastolic blood pressure (`bpsyst`,`bpdias`), and BMI (`bmi`).
```{r}
#| echo: false
#| eval: true
# read in dataset
dat<-read.csv("data/data_caerphilly_full.csv", sep = ";")

# make factors out of character variables
dat<- dat |> dplyr::select(mi, socclass, diabetes, smoking, cursmoke, fibrin, totchol, hdlchol, bpsyst, bpdias, bmi) |>
  mutate(mi = factor(mi, levels=c(0, 1), labels=c("No", "Yes")),
                    socclass = factor(socclass, levels=c("I", "II", "IIINM", "IIIM", "IV", "V")), 
                    diabetes=factor(diabetes, levels=c("No/uncertain", "Yes")), 
                    smoking=factor(smoking, levels=c("Never smoked", " Ex>5 years", "Ex 1-4 years" ,"<15 per day", ">15 per day")),
                    cursmoke = factor(cursmoke, levels=c("No", "Yes")))
  

head(dat)

```

## Purposeful selection - Step 1
Run univariable regressions including each independent variable at a time. Screen for inclusion using LR-test (for categorical variables) or Wald tests based on a high significance level, e.g. 0.2 or 0.25: 

::: {style="font-size: 60%;"}
```{r}
#| echo: false
#| eval: true
varname <- c()
pval <- c()
vars<-c("socclass", "diabetes",  "smoking", "cursmoke","fibrin", "totchol", "hdlchol", "bpsyst", "bpdias", "bmi" )

for (var in vars) {
  formula <- paste("mi ~", var )
  model<-glm(formula, data=dat, family=binomial(link="logit"))
  pval <- c(pval, anova(model, test="Chisq")[["Pr(>Chi)"]][2])
}
tab <- data.frame(vars,pval, pval<=0.20)
names(tab) <- c("Variable", "P-value LR-test", "Include (p<=0.2)")
kable(tab, digits=6)
```

:::

## Purposeful selection - Step 2
Fit multivariable model with all selected variables from step 1. Select for exclusion based LR-test (categorical variables) or Wald 
Selected for exclusion: `bmi`, `bpsyst`, `socclass`, `cursmoke` 

Let's keep track of global model statistics: 

```{r}
#| echo: true
#| eval: true
# Full model
mod_f<-glm(mi ~ socclass + diabetes + cursmoke + smoking + fibrin + totchol + hdlchol + bpsyst + bpdias + bmi, data=dat, family=binomial(link="logit"))
glance(mod_f)

```


## Purposeful selection - Step 3
Fit a restricting model excluding varaibles selected in step 2 for exclusion. Run a LR-test for the restricted model against the full model from step 2 using a more stringent $\alpha$-value  (e.g. 0.1). Also observe the AIC, BIC. 


::: {style="font-size: 80%;"}
```{r}
#| echo: true
#| eval: true
# Restricted model
mod_r<-glm(mi ~ diabetes + smoking + fibrin + totchol + hdlchol +  bpdias , data=dat, 
           family=binomial(link="logit"))
anova(mod_f, mod_r, test="Chisq")
glance(mod_r)

```
:::

## Purposeful selection - Step 3
Note: 

-  The P-value of the LR-test (0.46) suggest that the variables can be dropped
-  Both AIC and BIC are smaller than in the full model

Should the restriction be rejected, the full model from step 2 needs to be reduced step-wise. 

## Purposeful selection - Step 4
Assess the excluded variables in step 1 for re-inclusion: Add them to the model and include based on a Wald or LR-test again using the more stringent threshold. Also observe the AIC, BIC. 

This steps allow variables to re-enter that only reveal an association with the outcome in the presence of other covariates. 

In our case, none were excluded in step 1. 

## Purposeful selection - Step 5
In the model resulting from step 4, verify the the assumption of linear associations (on the logit scale) for continuous variables. 

We show two simple graphical methods to do this. The methods both compare an unrestricted association with exposure with a linearly restricted association, the first on the logit scale and the second on the probability scale. 


## Checking linearity in the logit
Method 1 consists of following steps: 


1. Create a factor variable assigning individuals to categories of the continuous variable (quartiles or quintiles recommended).  
2. Create a numeric variable assigning individuals the median/midpoint value within their category
3. Fit the regression model once with the factor variable and once with the numeric variable entered as linear term. 
4. Plot the the logits of both models (keeping values of other covariates fixed) against the medians/midpoints of the categories
5. Assume linearity if the association for the factor variable closely follows the linear association fo the grouped numeric variable.  



## Checking linearity in the logit 
Simulated data based on model: $\text{logit}(\pi)=1.5  + 0.3x +0.3x^2$
```{r}
#| echo: false
#| eval: true
set.seed(123457)
n <- 500
sim<-data.frame(x=rnorm(n))
sim$xs <- sim$x^2
sim$logit <- -1.5+ 0.3*sim$x + 0.3* sim$xs
sim$odds <- exp(sim$logit)
sim$prob <- sim$odds/(1+sim$odds)
sim$y <- as.integer(runif(n)<=sim$prob)

# define a factor variable representing quintils of x
quint <- quantile(sim$x, seq(0,1,0.20))
sim$x_q <- cut(sim$x, quint, include.lowest = TRUE)
# a numeric variable representing means within quintiles
qmed <- tapply(sim$x, sim$x_q, median)
sim$x_qm <- qmed[sim$x_q]
# run regressions
temp1<-glm(y ~ x_qm , data=sim, family=binomial(link="logit"))
temp2<-glm(y ~ x_q  , data=sim, family=binomial(link="logit"))
new <- unique(sim[,c("x_q","x_qm")])
new$fit1<-predict(temp1, newdata=new)
new$fit1_p<-predict(temp1, newdata=new)
new$fit2<-predict(temp2, newdata=new)


# Plots logit scale
ggplot(data=new, aes(x=x_qm)) +
  geom_vline(xintercept = quint, linetype="dotted",  color = "blue") +
  geom_line(aes(y=fit1), col="red") +
  geom_line(aes(y=fit2), col="blue") +
  xlab("x") + ylab("logit") +
  geom_text(data = NULL, x = -3.5, y = -.65, label = "Linear on quintile medians", color="red", size = 5, hjust="left" ) +
  geom_text(data = NULL, x = -3.5, y = -.55, label = "Unrestricted on quintiles", color="blue", size = 5, hjust="left") +
  theme_minimal() +
  theme(text = element_text(size = 20)) 

```



## Checking linearity in the logit 
Caerphilly dataset variable `fibrin`
```{r}
#| echo: false
#| eval: true
# fibrin
# define a factor variable representing quintils of fibrin
quint <- quantile(dat$fibrin, seq(0,1,0.2))
dat$fibrin_q <- cut(dat$fibrin, quint, include.lowest = TRUE)
# a numeric variable representing means within quintiles
qmed <- tapply(dat$fibrin, dat$fibrin_q, median)
dat$fibrin_qm <- qmed[dat$fibrin_q]
# run regressions
temp<-glm(mi ~ diabetes + smoking + fibrin + totchol + hdlchol +  bpdias , data=dat, family=binomial(link="logit"))
temp1<-glm(mi ~ diabetes + smoking + fibrin_q+ totchol + hdlchol +  bpdias , data=dat, family=binomial(link="logit"))
temp2<-glm(mi ~ diabetes + smoking + fibrin_qm + totchol + hdlchol +  bpdias , data=dat, family=binomial(link="logit"))
# anova(temp1, temp2, test="Chisq") # We can keep the restriction and assume linearity
new <- dat[1,] |> dplyr::select(diabetes, smoking, totchol,hdlchol, bpdias)
new <- cbind(new, fibrin_q=levels(dat$fibrin_q), fibrin_qm=qmed)
new$fit1<-predict(temp1, newdata=new)
new$fit2<-predict(temp2, newdata=new)
# Plots logit scale
ggplot(data=new, aes(x=fibrin_qm)) +
  geom_vline(xintercept = quint, linetype="dotted",  color = "blue") +
  geom_line(aes(y=fit1), col="red") +
  geom_line(aes(y=fit2), col="blue") +
  xlab("fibrin") + ylab("logit") +
    geom_text(data = NULL, x = 5, y = -1.55, label = "Linear on quintile medians", color="red", size = 5, hjust="left" ) +
  geom_text(data = NULL, x = 5, y = -1.45, label = "Unrestricted on quintiles", color="blue", size = 5, hjust="left") +
  theme_minimal() +
  theme(text = element_text(size = 20))

```

## Checking linearity in the logit 
Simulated data based on model: $\text{logit}(\pi)=1.5  + 0.3x +0.3x^2$
```{r}
#| echo: false
#| eval: true
# linear model
temp3<-glm(y ~ x , data=sim, family=binomial(link="logit"))
sim$fit3<-temp3$fitted.values

# probability scale
ggplot(data=sim, aes(x, y))+
  geom_point(alpha = 1/10) + 
  geom_smooth(method="loess", col="grey", se=FALSE) + 
  geom_line(aes(y=fit3, x=x), color="red") +
  xlab("x") + ylab("probability") +
  geom_text(data = NULL, x = -3.5, y = .7, label = "Linear in logit model", color="red", size = 5, hjust="left" ) +
  geom_text(data = NULL, x = -3.5, y = .8, label = "LOESS smooth", color="grey", size = 5, hjust="left") +
  theme_minimal() +
  theme(text = element_text(size = 20)) 
```


## Checking linearity in the logit 
Simulated data based on model: $\text{logit}(\pi)=\beta_0 + \beta_1 x +\beta_2 x^2$
```{r}
#| echo: false
#| eval: true
# probability scale
new <- dat[1,] |> dplyr::select(diabetes, smoking, totchol,hdlchol, bpdias)
new <- cbind(new, fibrin=seq(min(dat$fibrin), max(dat$fibrin), length.out=100))
new$fit<-predict(temp, newdata=new, type="response")
dat$mi_n <- as.numeric(dat$mi=="Yes")
ggplot(data=dat, aes(x=fibrin, y=mi_n))+
  geom_point(alpha = 1/10) + 
  geom_smooth(method="loess", col="grey", se=FALSE) + 
  geom_line(data=new, aes(y=fit, x=fibrin), color="red") +
  xlab("fibrin") + ylab("probability") +
  geom_text(data = NULL, x = 1, y = .7, label = "Linear in logit model", color="red", size = 5, hjust="left" ) +
  geom_text(data = NULL, x = 1, y = .8, label = "LOESS smooth", color="grey", size = 5, hjust="left") +
    theme_minimal() +
  theme(text = element_text(size = 20)) 
```


## Stepwise forward regression
run for caerphilly

## Caerphilly dataset 
stepwise for caerphilly

## Problems of stepwise regression
Generally not recommended

Criticisms by Harrell (ref)

Also investigator (partial) knowledge ignored, doesn't consider non-linear functional forms, interactions


##	Purposeful variable selection
As a viable approach for n>>p

Explain steps


##	Purposeful variable selection
As a viable approach for n>>p

Explain steps


##	Purposeful variable selection
As a viable approach for n>>p

Explain steps


## Prediction modeling
Special issues: 

- Often large number of candidate predictors -> risk of overfitting
- Assessing model performance
  - Discrimination / 

## Further reading: 
[García-Portugués E, Notes for Predictive Modeling](https://bookdown.org/egarpor/PM-UC3M/)

